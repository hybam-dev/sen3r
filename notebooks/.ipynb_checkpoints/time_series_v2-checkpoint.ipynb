{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sen3r-NcExplorer: from mpl_toolkits.basemap import Basemap FAILED!\n",
      "You can still proceed without plotting any maps.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from tsgen import TsGenerator\n",
    "from nc_explorer import NcExplorer\n",
    "\n",
    "tsgen = TsGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting RAW .SEN3 NetCDF4 without SNAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = {\n",
    "#     '/d_drive_data/S3/stations/12350000_fonte_boa/': ['/d_drive_data/S3/stations/12350000_fonte_boa_img/','/d_drive_data/A1_JM/areas/new_areas/12350000_fonte_boa.geojson'],\n",
    "#     '/d_drive_data/S3/stations/12900001_tefe/': ['/d_drive_data/S3/stations/12900001_tefe_img/','/d_drive_data/A1_JM/areas/new_areas/12900001_tefe.geojson'],\n",
    "#     '/d_drive_data/S3/stations/13100090_coari/': ['/d_drive_data/S3/stations/13100090_coari_img/','/d_drive_data/A1_JM/areas/new_areas/13100090_coari.geojson'],\n",
    "#     '/d_drive_data/S3/stations/15860000_borba_madeira/': ['/d_drive_data/S3/stations/15860000_borba_madeira_img/','/d_drive_data/A1_JM/areas/paper_areas/15860000_borba_madeira.geojson'],\n",
    "    '/d_drive_data/S3/stations/14100000_manacapuru/': ['/d_drive_data/S3/stations/14100000_manacapuru_img/','/d_drive_data/A1_JM/areas/paper_areas/14100000_manacapuru.geojson'],\n",
    "#     '/d_drive_data/S3/stations/17050001_obidos/': ['/d_drive_data/S3/stations/17050001_obidos_img/','/d_drive_data/A1_JM/areas/new_areas/17050001_obidos.geojson']\n",
    "#     '/d_drive_data/S3/stations/14910000_negro/': ['/d_drive_data/S3/stations/','/d_drive_data/A1_JM/areas/new_areas/14910000_negro.geojson'],\n",
    "#     '/d_drive_data/S3/stations/14900050_negro_2/': ['/d_drive_data/S3/stations/','/d_drive_data/A1_JM/areas/new_areas/14900050_negro_2.geojson']\n",
    "}\n",
    "# stations = {\n",
    "#     '/d_drive_data/S3/stations/AN1/': ['/d_drive_data/S3/stations/','/d_drive_data/A1_JM/artigo_SEN3R/ROIs/AN1.geojson'],\n",
    "#     '/d_drive_data/S3/stations/BCO/': ['/d_drive_data/S3/stations/','/d_drive_data/A1_JM/artigo_SEN3R/ROIs/BCO.geojson']\n",
    "#     '/d_drive_data/S3/stations/14100000_manacapuru/': ['/d_drive_data/S3/stations/14100000_manacapuru/','/d_drive_data/A1_JM/areas/paper_areas/14100000_manacapuru.geojson']\n",
    "#     '/d_drive_data/S3/stations/14900050_negro_19/': ['/d_drive_data/S3/stations/','/d_drive_data/A1_JM/areas/paper_areas/14900050_negro_19.geojson'],\n",
    "#     '/d_drive_data/S3/stations/14900050_negro_29/': ['/d_drive_data/S3/stations/','/d_drive_data/A1_JM/areas/paper_areas/14900050_negro_29.geojson'],\n",
    "#     '/d_drive_data/S3/stations/14900050_negro_37/': ['/d_drive_data/S3/stations/','/d_drive_data/A1_JM/areas/paper_areas/14900050_negro_37.geojson']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Processing: S3A_OL_2_WFR____20160425T134227_20160425T134427_20171030T154612_0119_003_238______MR1_R_NT_002\n",
      "Declaring class instance from: SEN3R:nc_explorer\n",
      "Reading valid NetCDF files inside image folder...\n",
      "Product set to WFR.\n",
      "Loading image bands into memory, this may take a while...\n",
      "extracting: LON / LAT\n",
      "extracting: OAA / OZA / SAA / SZA\n",
      "extracting: A865\n",
      "extracting: T865\n",
      "extracting: Oa01_reflectance\n",
      "extracting: Oa02_reflectance\n",
      "extracting: Oa03_reflectance\n",
      "extracting: Oa04_reflectance\n",
      "extracting: Oa05_reflectance\n",
      "extracting: Oa06_reflectance\n",
      "extracting: Oa07_reflectance\n",
      "extracting: Oa08_reflectance\n",
      "extracting: Oa09_reflectance\n",
      "extracting: Oa10_reflectance\n",
      "extracting: Oa11_reflectance\n",
      "extracting: Oa12_reflectance\n",
      "extracting: Oa16_reflectance\n",
      "extracting: Oa17_reflectance\n",
      "extracting: Oa18_reflectance\n",
      "extracting: Oa21_reflectance\n",
      "extracting: WQSF\n",
      "Saving DF: S3A_OL_2_WFR____20160425T134227_20160425T134427_20171030T154612_0119_003_238______MR1_R_NT_002\n",
      ">>> Finished in 11.98 second(s). <<<\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "\n",
    "# # WIN\n",
    "# in_dir = 'D:/S3/L2_WFR/'\n",
    "# out_dir = 'D:/processing/time-test/'\n",
    "# img_dir = 'D:/processing/time-test/'\n",
    "\n",
    "# UNIX\n",
    "in_dir = '/d_drive_data/S3/L2_WFR/'\n",
    "out_dir = '/d_drive_data/processing/time-test/'\n",
    "img_dir = '/d_drive_data/processing/time-test/'\n",
    "\n",
    "# poly = 'D:/A1_JM/areas/paper_areas/14100000_manacapuru.geojson'\n",
    "poly = '/d_drive_data/A1_JM/areas/paper_areas/15860000_borba_madeira.geojson'\n",
    "\n",
    "todo = tsgen.build_list_from_subset(in_dir)\n",
    "todo_fullpath = [os.path.join(in_dir,csv) for csv in todo]\n",
    "total = len(todo_fullpath)\n",
    "\n",
    "# ncxp = NcExplorer(input_nc_folder=img, product='wfr')\n",
    "# df = ncxp.get_data_in_poly(poly_path=poly, go_parallel=False)\n",
    "\n",
    "img = todo_fullpath[0]\n",
    "\n",
    "f_b_name = os.path.basename(img).split('.')[0]\n",
    "print(f'>>> Processing: {f_b_name}')\n",
    "\n",
    "ncxp = NcExplorer(input_nc_folder=img, product='wfr')\n",
    "\n",
    "# df = ncxp.get_data_in_poly(poly_path=poly, go_parallel=False)\n",
    "df = ncxp.get_data_in_poly(poly_path=poly, go_parallel=False)\n",
    "\n",
    "print(f'Saving DF: {f_b_name}')\n",
    "df.to_csv(os.path.join(out_dir, f_b_name+'.csv'), index=False)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "outputstr = f'>>> Finished in {round(t2 - t1, 2)} second(s). <<<'\n",
    "print(outputstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in stations:\n",
    "    \n",
    "    # LINUX\n",
    "    in_dir = '/d_drive_data/S3/L2_WFR'\n",
    "    out_dir = s\n",
    "    img_dir = stations[s][0]\n",
    "    poly = stations[s][1]\n",
    "    \n",
    "    todo = tsgen.build_list_from_subset(in_dir)\n",
    "    todo_fullpath = [os.path.join(in_dir,csv) for csv in todo]\n",
    "    total = len(todo_fullpath)\n",
    "    \n",
    "    info_string = f'Processing {total} files for station: {s} using polygon: {stations[s][1]}'\n",
    "    print(info_string)\n",
    "    os.system(f'telegram-send \\\"{info_string}\\\"')\n",
    "    \n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    for n, img in enumerate(todo_fullpath):\n",
    "\n",
    "        f_b_name = os.path.basename(img).split('.')[0]\n",
    "        print(f'>>> Processing: {n+1} of {total} ... {f_b_name}')\n",
    "        \n",
    "        if os.path.isfile(os.path.join(out_dir, f_b_name+'.csv')):\n",
    "            print('Skipped.')\n",
    "            continue\n",
    "        \n",
    "        ncxp = NcExplorer(input_nc_folder=img, product='wfr')\n",
    "\n",
    "        df = ncxp.get_data_in_poly(poly_path=poly, go_parallel=False)\n",
    "\n",
    "        # if df is not None:\n",
    "        print(f'Saving DF: {f_b_name}')\n",
    "        df.to_csv(os.path.join(out_dir, f_b_name+'.csv'), index=False)\n",
    "\n",
    "    t2 = time.perf_counter()\n",
    "    outputstr = f'>>> Finished in {round(t2 - t1, 2)} second(s). <<<'\n",
    "    print(outputstr)\n",
    "    os.system(f'telegram-send \\\"{outputstr}\\\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating post-processed CSVs from the raw extracted CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '-fin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Folder of files containing raw pixels extracted with GPT/SEN3R\n",
    "* Folder to save the processed files\n",
    "* Folder in which the plots should be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAMS 2016:2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "camscsvfolder = Path('/d_drive_data/A1_JM/artigo_SEN3R/2_mat_met/CAMS')\n",
    "# camscsvfolder = Path('D:/A1_JM/artigo_SEN3R/2_mat_met/CAMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "station2cams = [s for s in os.listdir(camscsvfolder) if s.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cams_station_dict = {}\n",
    "for s in station2cams:\n",
    "    sname = s.split('.')[0]\n",
    "    df = pd.read_csv(camscsvfolder/s)\n",
    "    cams_station_dict[sname] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['an1', 'borba_madeira', 'coari', 'fonte_boa', 'itacoatiara', 'manacapuru', 'negro', 'obidos', 'tefe'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cams_station_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/d_drive_data/A1_JM/artigo_SEN3R/2_mat_met/study_area/shp/15860000_borba_madeira.shp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # retrieve all files in folder\n",
    "# shps_path = '/d_drive_data/A1_JM/areas/paper_areas/shp'\n",
    "# files = os.listdir(shps_path)\n",
    "# # extract only the Shapefiles from the list\n",
    "# shps = [os.path.join(shps_path,f) for f in files if f.endswith('.shp')]\n",
    "# shps\n",
    "\n",
    "shps = ['/d_drive_data/A1_JM/artigo_SEN3R/2_mat_met/study_area/shp/15860000_borba_madeira.shp']\n",
    "# shps = ['/d_drive_data/A1_JM/areas/paper_areas/shp/14910000_negro.shp']\n",
    "# shps = ['/d_drive_data/A1_JM/areas/paper_areas/shp/14100000_manacapuru.shp']\n",
    "# shps = ['/d_drive_data/A1_JM/areas/paper_areas/shp/14900050_negro_19.shp',\n",
    "#         '/d_drive_data/A1_JM/areas/paper_areas/shp/14900050_negro_29.shp',\n",
    "#         '/d_drive_data/A1_JM/areas/paper_areas/shp/14900050_negro_37.shp']\n",
    "# shps = ['/d_drive_data/A1_JM/artigo_SEN3R/ROIs/SHP/AN1.shp',\n",
    "#         '/d_drive_data/A1_JM/artigo_SEN3R/ROIs/SHP/BCO.shp']\n",
    "shps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'manacapuru': '/d_drive_data/A1_JM/artigo_SEN3R/2_mat_met/study_area/shp/14100000_manacapuru.shp'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cams_n_shp = {\n",
    "    'manacapuru':'/d_drive_data/A1_JM/artigo_SEN3R/2_mat_met/study_area/shp/14100000_manacapuru.shp',\n",
    "    #'borba_madeira':'/d_drive_data/A1_JM/artigo_SEN3R/2_mat_met/study_area/shp/15860000_borba_madeira.shp', \n",
    "    #'obidos': '/d_drive_data/A1_JM/artigo_SEN3R/2_mat_met/study_area/shp/17050001_obidos.shp'\n",
    "             }\n",
    "cams_n_shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v-fin\n"
     ]
    }
   ],
   "source": [
    "tsgen._gettxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cams = True\n",
    "raw_dir = '/d_drive_data/S3/stations/'\n",
    "dest = '/d_drive_data/processing/linux/'\n",
    "\n",
    "for cs in cams_n_shp:  # Use CAMS\n",
    "#for station in shps:  \n",
    "\n",
    "    station = cams_n_shp[cs]\n",
    "    procstring = f'processing: {station}'\n",
    "    print(procstring)\n",
    "    os.system(f'telegram-send \\\"{procstring}\\\"')\n",
    "    \n",
    "#     # GET SHP CENTROIDS\n",
    "#     polygons = gpd.GeoDataFrame.from_file(station)\n",
    "#     polygons.geometry = polygons.representative_point()\n",
    "#     centroids = []\n",
    "#     for g in polygons['geometry']:\n",
    "#         q_lon, q_lat = g.coords[:][0]\n",
    "#         centroids.append((q_lon, q_lat))\n",
    "    \n",
    " \n",
    "    # GET SERIES SAVE PATH\n",
    "    station_name =    os.path.basename(station).split('.')[0]\n",
    "    in_dir =          os.path.join(raw_dir,station_name)\n",
    "    out_dir =         os.path.join(dest,station_name+f'_v{version}')\n",
    "    img_dir =         os.path.join(dest,station_name+f'_v{version}_img')\n",
    "    img_save_pth =    os.path.join(dest,station_name+f'_v{version}_img_dbscan')\n",
    "    series_save_pth = os.path.join(dest,station_name+f'_v{version}_img_dbscan_series')\n",
    "\n",
    "\n",
    "    # CREATE THE DIRECTORIES IF THEY DOESN'T EXIST YET\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(img_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(img_save_pth).mkdir(parents=True, exist_ok=True)\n",
    "    Path(series_save_pth).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    # GET LIST OF CSV FILES\n",
    "    todo = tsgen.build_list_from_subset(in_dir)\n",
    "    todo_fullpath = [os.path.join(in_dir,csv) for csv in todo]\n",
    "    \n",
    "    # Start timer\n",
    "    t1 = time.perf_counter()\n",
    "    \n",
    "    # Desclaring lists for further validation\n",
    "    checklist = {}\n",
    "    skiplst = []\n",
    "    donelst = []\n",
    "    \n",
    "    max_aot = False\n",
    "    # irmax = 0.001 # Negro\n",
    "    irmax = 0.2 # Generic\n",
    "    # irmax = 0.08 # Fonte Boa\n",
    "    # irmin = 0.001 # Manacapuru\n",
    "    \n",
    "    # Update RAW DFs\n",
    "    total = len(todo_fullpath)\n",
    "    \n",
    "    if use_cams:\n",
    "        # READ CAMS\n",
    "        df_cams = cams_station_dict[cs]\n",
    "        df_cams['pydate'] = pd.to_datetime(df_cams['Datetime'])\n",
    "    \n",
    "    for n,img in enumerate(todo_fullpath):\n",
    "        print(f'>>> Processing: {n+1} of {total} ... {img}')\n",
    "\n",
    "        \n",
    "        # fig params -------------------------------------------------\n",
    "        figdate = os.path.basename(img).split('____')[1].split('_')[0]\n",
    "        figtitl = os.path.basename(out_dir)+'_'+figdate\n",
    "        savpt_sctr = os.path.join(img_dir,figdate+'_0.png')\n",
    "        savpt_rrs = os.path.join(img_dir,figdate+'_1.png')\n",
    "        \n",
    "        if use_cams:\n",
    "            # Find the equivalent observation day in CAMS\n",
    "            dtlbl = datetime.strptime(figdate, '%Y%m%dT%H%M%S')\n",
    "            dtlbl = dtlbl.replace(hour=12, minute=0, second=0, microsecond=0)\n",
    "            cams_row = df_cams[df_cams['pydate'] == dtlbl]\n",
    "            cams_val = cams_row['AOD865'].values[0]\n",
    "            # if cams_val is empty no match was found\n",
    "            if not cams_val:\n",
    "                cams_val = False\n",
    "            \n",
    "        else:\n",
    "            cams_val = False\n",
    "                \n",
    "        \n",
    "        # reprocessing the raw CSVs and removing \n",
    "        # reflectances above the threshold in IR.\n",
    "        try:\n",
    "            dfpth, df = tsgen.update_csvs(csv_path=img,\n",
    "                                          glint=20.0,\n",
    "                                          #ir_min_threshold=irmin,\n",
    "                                          ir_max_threshold=irmax,\n",
    "                                          savepath=out_dir,\n",
    "                                          max_aot=max_aot,\n",
    "                                          cams_val=cams_val)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"type error: \" + str(e))\n",
    "            skiplst.append(img)\n",
    "            continue\n",
    "\n",
    "        # The KDE needs at least two different reflectance values to work.\n",
    "        if dfpth == 'KDE_fail':\n",
    "            skiplst.append(img)\n",
    "            continue\n",
    "\n",
    "    #     try:\n",
    "    #         dfpth, df = tsgen.update_csvs(csv_path=img,savepath=out_dir,threshold=0.2)\n",
    "    #     except Exception as e:\n",
    "    #         print(\"type error: \" + str(e))\n",
    "    #         print(f'Skipping CSV for lack of data: {figdate}')\n",
    "    #         skiplst.append(img)\n",
    "    #         continue\n",
    "\n",
    "    #     dfpth, df = tsgen.update_csvs(csv_path=img,\n",
    "    #                                   savepath=out_dir,\n",
    "    #                                   threshold=0.2)\n",
    "\n",
    "        if len(df) < 1:\n",
    "            print(f'Skipping empty CSV: {dfpth}')\n",
    "            skiplst.append(img)\n",
    "            continue\n",
    "        else:\n",
    "            donelst.append(img)\n",
    "\n",
    "\n",
    "        # generate plot v1 --------------------------\n",
    "    #     tsgen.plot_single_sktr(\n",
    "    #         xdata=df['Oa08_reflectance:float'],\n",
    "    #         ydata=df['Oa21_reflectance:float'],\n",
    "    #         xlabel='Oa08: 665 nm',\n",
    "    #         ylabel='Oa17: 865 nm',\n",
    "    #         color=df['T865:float'],\n",
    "    #         clabel='T865',\n",
    "    #         title=figtitl,\n",
    "    #         savepathname=savpt)\n",
    "\n",
    "        # generate plot v3 --------------------------\n",
    "        tsgen.plot_sidebyside_sktr(x1_data=df['Oa08_reflectance:float'],\n",
    "                                   y1_data=df['Oa17_reflectance:float'],\n",
    "                                   x2_data=df['Oa08_reflectance:float'],\n",
    "                                   y2_data=df['Oa17_reflectance:float'],\n",
    "                                   x_lbl='RED: Oa08 (665nm)',\n",
    "                                   y_lbl='NIR: Oa17 (865nm)',\n",
    "                                   c1_data=df['A865:float'],\n",
    "                                   c1_lbl='Aer. Angstrom Expoent (A865)',\n",
    "                                   c2_data=df['T865:float'],\n",
    "                                   c2_lbl='Aer. Optical Thickness (T865)',\n",
    "                                   title=f'{os.path.basename(out_dir)} WFR {figdate} RED:Oa08(665nm) x NIR:Oa17(865nm)',\n",
    "                                   savepathname=savpt_sctr)\n",
    "\n",
    "        tsgen.s3l2_custom_reflectance_plot(df=df,\n",
    "                                           figure_title=f'{figdate}\\n',\n",
    "                                           c_lbl='Aer. Optical Thickness (T865)',\n",
    "                                           save_title=savpt_rrs)\n",
    "\n",
    "    t2 = time.perf_counter()\n",
    "    outputstr = f'>>> Finished in {round(t2 - t1, 2)} second(s). <<<'\n",
    "    print(outputstr)\n",
    "    os.system(f'telegram-send \\\"{outputstr}\\\"')\n",
    "    \n",
    "    # Generating excel file from the post-processed data\n",
    "    wdir = out_dir\n",
    "    todo = tsgen.build_list_from_subset(wdir)\n",
    "    todo_fullpath = [os.path.join(wdir,txt) for txt in todo]\n",
    "    \n",
    "    # Converting and saving the list of mean values into a XLS excel file.\n",
    "    data = tsgen.generate_time_series_data(wdir,todo)\n",
    "\n",
    "    series_df = pd.DataFrame(data=data)\n",
    "    # Delete these row indexes from dataFrame\n",
    "    # indexNames = series_df[series_df['B17-865'] > irmax].index\n",
    "    # indexNames = series_df[series_df['B17-865'] < irmin].index\n",
    "    # series_df.drop(indexNames, inplace=True)\n",
    "    \n",
    "    # create empty excel\n",
    "    path = os.path.join(dest,station_name+f'_v{version}.xlsx')\n",
    "    wb = openpyxl.Workbook()\n",
    "    wb.save(path)\n",
    "\n",
    "    # open the empty file and fill it up\n",
    "    sheet = f'v{version}'\n",
    "    book = openpyxl.load_workbook(path)\n",
    "    writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "    writer.book = book\n",
    "\n",
    "    # LINUX\n",
    "    series_df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/d_drive_data/S3/stations/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating excel file from the post-processed data\n",
    "wdir = out_dir\n",
    "todo = tsgen.build_list_from_subset(wdir)\n",
    "todo_fullpath = [os.path.join(wdir,txt) for txt in todo]\n",
    "\n",
    "# Converting and saving the list of mean values into a XLS excel file.\n",
    "data = tsgen.generate_time_series_data(wdir,todo)\n",
    "\n",
    "series_df = pd.DataFrame(data=data)\n",
    "# Delete these row indexes from dataFrame\n",
    "# indexNames = series_df[series_df['B17-865'] > irmax].index\n",
    "# indexNames = series_df[series_df['B17-865'] < irmin].index\n",
    "# series_df.drop(indexNames, inplace=True)\n",
    "\n",
    "# create empty excel\n",
    "path = os.path.join(dest,station_name+f'_v{version}.xlsx')\n",
    "wb = openpyxl.Workbook()\n",
    "wb.save(path)\n",
    "\n",
    "# open the empty file and fill it up\n",
    "sheet = f'v{version}'\n",
    "book = openpyxl.load_workbook(path)\n",
    "writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "# LINUX\n",
    "series_df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the empty file and fill it up\n",
    "sheet = f'v{version}'\n",
    "book = openpyxl.load_workbook(path)\n",
    "writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "# LINUX\n",
    "series_df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new CSVs and plots based in the RAW data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfpth, df = tsgen.update_csvs(csv_path=todo_fullpath[0],savepath=out_dir,threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1 = time.perf_counter()\n",
    "skiplst = []\n",
    "donelst = []\n",
    "\n",
    "total = len(todo_fullpath)\n",
    "for n,img in enumerate(todo_fullpath):\n",
    "    print(f'>>> Processing: {n+1} of {total} ... {img}')\n",
    "    \n",
    "    # reprocessing the raw CSVs and removing \n",
    "    # reflectances above the threshold in IR.\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        dfpth, df = tsgen.update_csvs(csv_path=img,savepath=out_dir,threshold=0.2,glint=20.0)\n",
    "    except Exception as e:\n",
    "        print(\"type error: \" + str(e))\n",
    "        skiplst.append(img)\n",
    "        continue\n",
    "\n",
    "    # The KDE needs at least two different reflectance values to work.\n",
    "    if dfpth == 'KDE_fail':\n",
    "        skiplst.append(img)\n",
    "        continue\n",
    "    \n",
    "#     try:\n",
    "#         dfpth, df = tsgen.update_csvs(csv_path=img,savepath=out_dir,threshold=0.2)\n",
    "#     except Exception as e:\n",
    "#         print(\"type error: \" + str(e))\n",
    "#         print(f'Skipping CSV for lack of data: {figdate}')\n",
    "#         skiplst.append(img)\n",
    "#         continue\n",
    "\n",
    "#     dfpth, df = tsgen.update_csvs(csv_path=img,\n",
    "#                                   savepath=out_dir,\n",
    "#                                   threshold=0.2)\n",
    "    \n",
    "    if len(df) < 1:\n",
    "        print(f'Skipping empty CSV: {dfpth}')\n",
    "        skiplst.append(img)\n",
    "        continue\n",
    "    else:\n",
    "        donelst.append(img)\n",
    "    \n",
    "    \n",
    "    # fig params -------------------------------------------------\n",
    "    figdate = os.path.basename(img).split('____')[1].split('_')[0]\n",
    "    figtitl = os.path.basename(out_dir)+'_'+figdate\n",
    "    savpt_sctr = os.path.join(img_dir,figdate+'_0.png')\n",
    "    savpt_rrs = os.path.join(img_dir,figdate+'_1.png')\n",
    "    \n",
    "    print(f'Generating image: {savpt_sctr}')\n",
    "    \n",
    "    # generate plot v1 --------------------------\n",
    "#     tsgen.plot_single_sktr(\n",
    "#         xdata=df['Oa08_reflectance:float'],\n",
    "#         ydata=df['Oa21_reflectance:float'],\n",
    "#         xlabel='Oa08: 665 nm',\n",
    "#         ylabel='Oa17: 865 nm',\n",
    "#         color=df['T865:float'],\n",
    "#         clabel='T865',\n",
    "#         title=figtitl,\n",
    "#         savepathname=savpt)\n",
    "    \n",
    "    # generate plot v3 --------------------------\n",
    "    tsgen.plot_sidebyside_sktr(x1_data=df['Oa08_reflectance:float'],\n",
    "                               y1_data=df['Oa17_reflectance:float'],\n",
    "                               x2_data=df['Oa08_reflectance:float'],\n",
    "                               y2_data=df['Oa17_reflectance:float'],\n",
    "                               x_lbl='RED: Oa08 (665nm)',\n",
    "                               y_lbl='NIR: Oa17 (865nm)',\n",
    "                               c1_data=df['A865:float'],\n",
    "                               c1_lbl='Aer. Angstrom Expoent (A865)',\n",
    "                               c2_data=df['T865:float'],\n",
    "                               c2_lbl='Aer. Optical Thickness (T865)',\n",
    "                               title=f'{os.path.basename(out_dir)} WFR {figdate} RED:Oa08(665nm) x NIR:Oa17(865nm)',\n",
    "                               savepathname=savpt_sctr)\n",
    "    \n",
    "    print(f'Generating image: {savpt_rrs}')\n",
    "    \n",
    "    tsgen.s3l2_custom_reflectance_plot(df=df,\n",
    "                                       figure_title=figdate,\n",
    "                                       c_lbl='Aer. Optical Thickness (T865)',\n",
    "                                       save_title=savpt_rrs)\n",
    "    \n",
    "t2 = time.perf_counter()\n",
    "outputstr = f'>>> Finished in {round(t2 - t1, 2)} second(s). <<<'\n",
    "print(outputstr)\n",
    "os.system(f'telegram-send \\\"{outputstr}\\\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating mean values dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = out_dir\n",
    "\n",
    "todo = tsgen.build_list_from_subset(wdir)\n",
    "\n",
    "todo_fullpath = [os.path.join(wdir,txt) for txt in todo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting and saving the list of mean values into a XLS excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tsgen.generate_time_series_datav2(wdir,todo)\n",
    "\n",
    "series_df = pd.DataFrame(data=data)\n",
    "\n",
    "path = '/d_drive_data/processing/linux/manacapuru_v10.xlsx'\n",
    "# path = f'/d_drive_data/processing/linux/{os.path.basename(out_dir)}.xlsx'\n",
    "# sheet = f'{os.path.basename(out_dir)}higlint'\n",
    "sheet = f'v10g20'\n",
    "\n",
    "book = load_workbook(path)\n",
    "writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "# LINUX\n",
    "series_df.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "# WIN\n",
    "# series_df.to_excel(f'D:\\\\processing\\\\win\\\\{os.path.basename(out_dir)}.xlsx', sheet_name=f'{os.path.basename(out_dir)}')\n",
    "\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAMS+DBSCAN processing for a list of stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "\n",
    "ncxp = NcExplorer(initialize=False, external_use=True)\n",
    "\n",
    "def nc_dt2num(date):\n",
    "    # https://stackoverflow.com/questions/39997314/write-times-in-netcdf-file\n",
    "    units = \"hours since 1900-01-01 00:00:00.0\"\n",
    "    calendar = \"gregorian\"\n",
    "    return netCDF4.date2num(date, units=units, calendar=calendar)\n",
    "\n",
    "def get_cams_band_by_time(numeric_date, cams_time_array):\n",
    "    pos = np.where(cams_time_array == numeric_date)[0]\n",
    "    return pos[0]\n",
    "\n",
    "def find_cams_val(number_date, cams_time_array, query_lon=-60.8911,query_lat=-3.5726):\n",
    "    # Manacapuru Centroid\n",
    "    # query_lon, query_lat = -60.8911, -3.5726\n",
    "    # query for the corret day position inside the CAMS time array\n",
    "    day_position = get_cams_band_by_time(number_date, cams_time_array)\n",
    "    # extract CAMS AOD data at this day\n",
    "    aod_band = cams_nc.variables['aod865'][day_position][:]\n",
    "    # query the AOD pixel value over the target coordinates\n",
    "    cams_val = ncxp.get_point_data_in_single_band(aod_band, \n",
    "                                                 lon=lon_grid, \n",
    "                                                 lat=lat_grid,\n",
    "                                                 target_lon=query_lon,\n",
    "                                                 target_lat=query_lat)[1]\n",
    "    \n",
    "    return cams_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating iterable list of NC paths\n",
    "\n",
    "ncp = '/d_drive_data/CAMS/'\n",
    "ncps = os.listdir(ncp)\n",
    "ncps = [os.path.join(ncp,nc) for nc in ncps]\n",
    "\n",
    "# Storing NC data inside dicts accessible by YEAR\n",
    "\n",
    "lons = {}\n",
    "lats = {}\n",
    "cm_time = {}\n",
    "cams_nc = {}\n",
    "lon_grid = {}\n",
    "lat_grid = {}\n",
    "\n",
    "for ncp in ncps:\n",
    "    \n",
    "    print(f'extracting data for file: {ncp}')\n",
    "    year = int(os.path.basename(ncp).split('.')[0].split('_')[1])\n",
    "    cams_nc[year] = netCDF4.Dataset(ncp,'r')\n",
    "\n",
    "    # get the longitude information\n",
    "    lons[year] = cams_nc[year].variables['longitude'][:]\n",
    "    # get the latitude information\n",
    "    lats[year] = cams_nc[year].variables['latitude'][:]\n",
    "    # extract the time dimension\n",
    "    cm_time[year] = cams_nc[year].variables['time']\n",
    "\n",
    "    # creating 2D grids for further plotting\n",
    "    lon_grid[year], lat_grid[year] = np.meshgrid(lons[year], lats[year])\n",
    "\n",
    "cm_time.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
